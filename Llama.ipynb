{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5052cb99-e948-42d6-8444-01b23545986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02eec1df-75ab-4ac3-998a-fec45a961cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000049c4530615e68b898b3e0306630d</td>\n",
       "      <td>53a66119381d887197c67ccfe3ef6670: hi 1c8edb8bf...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000604306a283600b730276a2039471</td>\n",
       "      <td>a9b326df4e6da61c5b6f5e1058be83a2: b8810fee2f4a...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000133dbd971ffb8f723fc61ba977ca0</td>\n",
       "      <td>8f1d151f40bd785177dec682f5407c4e: hey 3b8f9119...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001347c00d419eb537c0692e6e58eba</td>\n",
       "      <td>e2bd430b29412d9267886e187ba28075: say asl and ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000161e288cf8dfc468fe86d6d4af2d4</td>\n",
       "      <td>b035925d950f4a032b68dd0844ff8413: h b035925d95...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222050</th>\n",
       "      <td>fffe4d1b08952afb8627a9b594f913c7</td>\n",
       "      <td>e5a96ed432ed5041be76d3fb1784fb95: do you want ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222051</th>\n",
       "      <td>ffff2d0e314610b1df596482d806ada9</td>\n",
       "      <td>eccc65c89e622a83cfec5827c16391de: haiiiiiiiii....</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222052</th>\n",
       "      <td>ffff38287b6013960b9e96e08f85526a</td>\n",
       "      <td>a9343d850a27be6ed37f176bc2ce589b: hi a9343d850...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222053</th>\n",
       "      <td>ffff74f40b58182a2521235b9db901d4</td>\n",
       "      <td>7bc167d759d9c56d43d1d46575433d35: hey 169b2106...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222054</th>\n",
       "      <td>ffffe01fc5b03a8d6b8c929d595644d9</td>\n",
       "      <td>a5b6dda9425e1d67e37432b48db51a57: anyone famil...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222055 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id  \\\n",
       "0       000049c4530615e68b898b3e0306630d   \n",
       "1       0000604306a283600b730276a2039471   \n",
       "2       000133dbd971ffb8f723fc61ba977ca0   \n",
       "3       0001347c00d419eb537c0692e6e58eba   \n",
       "4       000161e288cf8dfc468fe86d6d4af2d4   \n",
       "...                                  ...   \n",
       "222050  fffe4d1b08952afb8627a9b594f913c7   \n",
       "222051  ffff2d0e314610b1df596482d806ada9   \n",
       "222052  ffff38287b6013960b9e96e08f85526a   \n",
       "222053  ffff74f40b58182a2521235b9db901d4   \n",
       "222054  ffffe01fc5b03a8d6b8c929d595644d9   \n",
       "\n",
       "                                                     text sentiment  label  \n",
       "0       53a66119381d887197c67ccfe3ef6670: hi 1c8edb8bf...  Positive      0  \n",
       "1       a9b326df4e6da61c5b6f5e1058be83a2: b8810fee2f4a...  Negative      0  \n",
       "2       8f1d151f40bd785177dec682f5407c4e: hey 3b8f9119...  Positive      0  \n",
       "3       e2bd430b29412d9267886e187ba28075: say asl and ...  Positive      0  \n",
       "4       b035925d950f4a032b68dd0844ff8413: h b035925d95...  Negative      0  \n",
       "...                                                   ...       ...    ...  \n",
       "222050  e5a96ed432ed5041be76d3fb1784fb95: do you want ...  Negative      0  \n",
       "222051  eccc65c89e622a83cfec5827c16391de: haiiiiiiiii....  Negative      0  \n",
       "222052  a9343d850a27be6ed37f176bc2ce589b: hi a9343d850...  Positive      0  \n",
       "222053  7bc167d759d9c56d43d1d46575433d35: hey 169b2106...  Positive      0  \n",
       "222054  a5b6dda9425e1d67e37432b48db51a57: anyone famil...  Negative      0  \n",
       "\n",
       "[222055 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv('dataset_labeled.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a658ecaf-d3e9-4f61-b3ab-30e146985989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"meta-llama/Llama-3.2-1B\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4289b1f-0879-44b1-a749-4c2d987f218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "df = Dataset.from_pandas(dataset[['text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56634919-6d5f-4350-b1aa-68a6b9f67f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.pad_token = tokenizer.eos_token  # Assign eos_token as the pad_token\n",
    "#     model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Define and add the padding token if it's not already defined\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58b32d64-8026-4b78-a2da-661e690fa724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/222055 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4: Define the tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding = 'max_length', truncation=True, max_length = 64)\n",
    "\n",
    "# Step 5: Apply tokenization to all rows\n",
    "tokenized_datasets = df.map(tokenize_function, batched=True, batch_size = 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb45f81e-f959-488e-8c68-d6b451338df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3bd8f65-bb52-42c9-a00b-b876be8c1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets (70/30 split)\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.3)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbf314c6-a665-44e3-b971-3d609f40ac6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 155438\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc1b5814-cc08-486e-91b1-b8e1d886eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14f5a4-b159-4f37-ba7a-a642d5b44904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e93ce015fe4f379dd6e4cb8d679d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='19428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    4/19428 08:40 < 1403:52:13, 0.00 it/s, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load the required metrics\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "# Define a function to compute multiple metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)  # Get the predicted class\n",
    "\n",
    "    # Calculate each metric individually\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"]\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    logging_steps=2000,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"no\", \n",
    ")\n",
    "\n",
    "# Define the collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58540e52-d3c6-46f5-890b-3acf57791b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d654e96-ca81-4472-94c8-b6999612dbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
